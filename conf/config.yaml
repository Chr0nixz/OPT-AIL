exp_name: ''
project_name: ${env.name}

cuda_deterministic: False
device: ??? # to be specified later

gamma: 0.99
seed: 0
pretrain: null

num_seed_steps: 0 # Don't need seeding for IL (Use 1000 for RL)
only_expert_states: False

train:
  batch: 256
  use_target: True
  soft_update: True

expert:
  demos: 10
  subsample_freq: 1

eval:
  policy: 
  threshold:
  use_baselines: False
  eps: 10
  transfer: False
  expert_env: ''

env:
  replay_mem: 1000000
  initial_mem: 2000
  eps_steps: 1000
  eps_window: 100
  learn_steps: 5e5
  eval_interval: 5e3

  # use pixels
  from_pixels: False

method:
  type: il

# Extra args
log_interval: 100  # Log every this many steps
log_dir: logs/
save_interval: 5 # Save networks every this many epochs
hydra_base_dir: ""
eval_only: False

# Replay buffer save/load
save_replay_buffer: False  # Whether to save replay buffer when saving models
load_replay_buffer: False  # Whether to load saved replay buffer at start
buffer_folder: /home/ubuntu/xutian/mb_ail/buffers/  # Folder to save/load replay buffers
model_folder: /home/ubuntu/xutian/mb_ail/saved_model_hyper/

# Do offline learning
offline: False
# Number of actor updates per env step
num_actor_updates: 1

defaults:
  - method: il
  - agent: mb_ail
  - env: finger_spin